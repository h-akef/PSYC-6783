---
title: "PSYC 6783 Code Book"
author: "Huda Akef"
date: "4/12/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


```{r function-check-for-packages, include=FALSE}

# make sure we can load packages 
# (thanks to https://gist.github.com/smithdanielle/9913897)
load_or_install_packages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, 
                     dependencies = TRUE,
                     repos="http://cloud.r-project.org/")
  sapply(pkg, require, character.only = TRUE)
}

```


```{r load-packages, message=FALSE, results="hide"}
# specify which packages we'll need
required_packages = c("usethis",
                      "gitcreds",
                      "devtools",
                      "stringr",
                      "magrittr",
                      "tidyverse",
                      "knitr",
                      "grid",
                      "gridExtra",
                      "textreadr",
                      "gitignore"
                      )

# install them (if necessary) and load them
load_or_install_packages(required_packages)
devtools::install_github("hadley/emo")
```

Now, we convert that single phrase "inshaaAllah" in a group of documents in a folder using a loop. 
**Note: have to type in Arabic text with parentheses here directly, copying from other text file doesn't seem to format parentheses correctly!**

```{r isa adjustments}

doctext <- readLines("UB06.txt", encoding="UTF-8")
doctext2<- doctext
doctextflat <- doctext %>% str_flatten()
insha <-"إنشاء"
insha2 <- "انشاء"
insha_correct <- "إن شاء"

testtext <- readLines("test.txt", encoding="UTF-8")

str_detect(testtext,insha_correct)
str_detect(testtext,insha)
str_detect(testtext,insha2)

testcorr <- str_replace_all(testtext,insha,insha_correct)
testcorr <- str_replace_all(testcorr,insha2,insha_correct) 

str_detect(testcorr,insha_correct)
str_detect(testcorr,insha)
str_detect(testcorr,insha2)

write.table(doctext2dash, file="UB07_isaPhrased.txt", row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE)

```



```{r convert phrases in multiple files}
fileNames <- list.files(path ="./transcripts",pattern="*noQ.txt") #getting file names for transcript files with questions removed
dashedFiles <- paste("dash.",fileNames, sep="")

# create empty data frame for storing data and results of detecting unwanted phrases

detection_initial <- data.frame(file=character(),checkisa1=logical(),checkisa2=logical(), checkisa=logical(), checkahl=logical(), checksbh=logical(),checkmsa=logical(),stringsAsFactors = FALSE)

detection <- data.frame(file=character(),data=character(),checkisa1=logical(),checkisa2=logical(), checkisa=logical(), checkahl=logical(), checksbh=logical(),checkmsa=logical(),stringsAsFactors = FALSE)

  insha <-"إنشاء"
  insha2 <- "انشاء"
  insha_correct <- "إن شاء"
  
  isa <- "إن شاء الله"
  isa_dash <- "إن-شاء-الله"
  
  ahl <- "الحمد لله"
  ahl_dash <- "الحمد-لله"
 
  sbh <- "سبحان الله"
  sbh_dash <- "سبحان-الله"
  
  msa <- "ما شاء الله"
  msa_dash <- "ما-شاء-الله"
  
setwd("./transcripts")

for(i in 1:length(fileNames))
{
  tempdata <- read_lines(fileNames[i],skip=0) 
  tempdata[tempdata == "  "] <- " " #removing double spaces
  tempdata <- tempdata %>% str_flatten()
  
  detection[i,1]<-fileNames[i]
  detection_initial[i,1]<-fileNames[i]
  
  # initial detection of unwanted phrases
  detection_initial[i,2]<-  str_detect(tempdata,insha)
  detection_initial[i,3]<-  str_detect(tempdata,insha2)
  detection_initial[i,4]<-  str_detect(tempdata,isa)
  detection_initial[i,5]<-  str_detect(tempdata,ahl)
  detection_initial[i,6]<-  str_detect(tempdata,sbh)
  detection_initial[i,7]<-  str_detect(tempdata,msa)
  
  #converting incorrect spellings of inshaaAllah
  tempdata <- str_replace_all(tempdata,insha,insha_correct)
  tempdata <- str_replace_all(tempdata,insha2,insha_correct) 
 
   #replacing and dashing phrases
  tempdata <- str_replace_all(tempdata,isa,isa_dash) 
  tempdata <- str_replace_all(tempdata,ahl,ahl_dash)
  tempdata <- str_replace_all(tempdata,sbh,sbh_dash)
  tempdata <- str_replace_all(tempdata,msa,msa_dash)
  
  #adding edited trasncript to data frame
  detection[i,2]<-  tempdata
  
  #detecting any lingering incorrect phrases
  detection[i,3]<-  str_detect(tempdata,insha)
  detection[i,4]<-  str_detect(tempdata,insha2)
  detection[i,5]<-  str_detect(tempdata,isa)
  detection[i,6]<-  str_detect(tempdata,ahl)
  detection[i,7]<-  str_detect(tempdata,sbh)
  detection[i,8]<-  str_detect(tempdata,msa)
 
  
  write.table(tempdata, file=dashedFiles[i], row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE) 
}
 
 

```

This is the code to convert the inshaaAllah phrase in an entire document --> success!

```{r phrase converter per document}

doctext <- readLines("UB07_noQ.txt", encoding="UTF-8")
doctext2<- doctext
docflat <- doctext %>% str_flatten()
isa <- "إن شاء الله"
isa_dash <- "إن-شاء-الله"
#hashes <- "#######################"
#str_replace_all(docflat,hashes,"#")
doctext2dash <- str_replace_all(doctext2,isa,isa_dash) 
str_detect(doctext2dash,isa_dash)
write.table(doctext2dash, file="UB07_isaPhrased.txt", row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE)
#### This works!

#checking with flattened string
str_detect(docflat,isa)
docflatdash <- str_replace_all(docflat,isa,isa_dash)
str_detect(docflatdash,isa_dash) #this works! just need to make sure that str replace is assigned to new variable


#testing with single line
exampleText <- "سواء المدرسة بمصاريفها.. النادي... بس فأعتقد أن أنا يعني أب كويس إن شاء الله يعني"
str_detect(exampleText,isa)
str_replace_all(exampleText,isa,isa_dash)
str_detect(exampleText,isa_dash)
#success!
#Hi!! this is a test
```


```{r phrase converter}
#testing withe str_replace_all

test_text <-  " أيوة أنا إن شاء الله جاية و بعدين هروح إن شاء الله"
new_text <- test_text
isa <- "إن شاء الله"
isa_dash <- "إن-شاء-الله"
str_replace_all(new_text,isa,isa_dash)

#success!
```


```{r import docx, warning=FALSE, eval=FALSE}
 library(textreadr)
#setwd("~/Documents/UConn/15- Spring 2022/PSYC 6783/Analysis Tools")
## .docx
#docx_t <- system.file("test.docx",
#package = "textreadr")  # not necessary ad did not work
test <- read_document("UB03.docx") # worked! seems to importan as character vector separated by empty lines
test2 <- read_document("UB03.docx", combine=TRUE) #yay! worked and put it all in one string
#test2
write.table(test2, file="test2.txt", row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE)
write.table(test, file="test.txt", row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE)
#while combining into a single string with combine=TRUE may be better for some things, it will not include separate lines when writing into a text file, with the noncombined dataframe was exported into a text file maintaining line structure but no empty lines
test3 <- read_document("UB03.docx",remove.empty=FALSE,skip=0) #reads empty lines as empty rows
write.table(test3, file="test3.txt", row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE) #this works and includes empty lines
#other option to put in something instead of empty lines
test4 <- test3
test4[test4 == ""] <- "##########" 
write.table(test4, file="test4.txt", row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE) #perfect!

#now need loop to do this will all files
#the following reads all file names in a folder and changes extension. 

docx_files <- list.files(path = "~/Documents/UConn/15- Spring 2022/PSYC 6783/Analysis Tools/Final Complete Transcripts",pattern="*.docx")

noext_files <- substr(docx_files,1,nchar(docx_files)-5)

txt_files <- paste(noext_files, ".txt",sep="")

#loop function to read all files and write them as txt works!!!

#setwd("~/Documents/UConn/15- Spring 2022/PSYC 6783/Analysis Tools/Final Complete Transcripts")
for(i in 1:length(docx_files))
{
  tempdata <- read_document(docx_files[i],remove.empty=FALSE,skip=0) 
  tempdata[tempdata == ""] <- "#######################" 
  write.table(tempdata, file=txt_files[i], row.names = FALSE, col.names=FALSE, fileEncoding = "UTF-8", quote=FALSE) 
}
  
```


```{r ArabicTest2, results = "hide", warning=FALSE}
arabicTest <- readLines("UB_RTest.txt",encoding='UTF-8')
arabicTest # aaaand this worked!! yippee!!
arabicTest2 <- readLines("UB06.txt",encoding='UTF-8') #bigger text file include some English words within Arabic text
arabicTest2 # this also worked well, loks like delimiter is new line
# now trying some string operations
#arabicTest2 %>% str_count(pattern="حاجة")
#does not work, weird output 
#head(arabicTest2)
UB06flat <- arabicTest2 %>% str_flatten() #flattening is the key!
UB06flat
UB06flat %>% str_count(pattern = "حاجة") #works and results verified, there are indeed 33 instances of حاجةin the file
```
